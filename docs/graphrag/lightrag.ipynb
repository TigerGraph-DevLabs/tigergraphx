{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a421f5f-208d-47ef-9b3c-a1cad761261a",
   "metadata": {},
   "source": [
    "[LightRAG](https://github.com/HKUDS/LightRAG) is an open-source RAG system that enhances LLMs by integrating graph-based structures into text indexing and retrieval. It overcomes the limitations of traditional RAG systems, such as fragmented answers and weak contextual awareness, by enabling dual-level retrieval for more comprehensive knowledge discovery. With support for incremental data updates, LightRAG ensures timely integration of new information while delivering improved retrieval accuracy and efficiency.\n",
    "\n",
    "To run this Jupyter Notebook, you can download the original `.ipynb` file from [lightrag.ipynb](https://github.com/tigergraph/tigergraphx/tree/main/docs/graphrag/lightrag.ipynb).\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Before proceeding, complete the installation and setup steps outlined in the [Installation Guide](../getting_started/installation.md), including:\n",
    "\n",
    "- Setting up Python and TigerGraph. See the [Requirements](../getting_started/installation.md#requirements) section for details.\n",
    "- Installing TigerGraphX and its development dependencies. See the [Development Installation](../getting_started/installation.md#development-installation) section.\n",
    "- Setting the required environment variables:  \n",
    "  \n",
    "\n",
    "   ```bash\n",
    "   export TG_HOST=https://127.0.0.1\n",
    "   export TG_USERNAME=tigergraph\n",
    "   export TG_PASSWORD=tigergraph\n",
    "   export OPENAI_API_KEY=<Your OpenAI API Key>\n",
    "   ```\n",
    "\n",
    "   These variables configure the connection to the TigerGraph server and OpenAI.\n",
    "\n",
    "---\n",
    "\n",
    "## Implementing Graph and Vector Storage with TigerGraph\n",
    "\n",
    "LightRAG abstracts storage into components such as graph storage, key-value storage, and vector storage. You can explore the base classes **BaseGraphStorage**, **BaseVectorStorage**, and **BaseKVStorage** in the [source code](https://github.com/HKUDS/LightRAG/blob/main/lightrag/base.py).\n",
    "\n",
    "This section demonstrates how to use **TigerGraphX** to implement:\n",
    "1. **`BaseGraphStorage`** for storing and retrieving graph data in TigerGraph.\n",
    "2. **`BaseVectorStorage`** for storing vector data and performing vector searches using TigerGraph's **TigerVector** feature.\n",
    "\n",
    "### Implementing Graph Storage with TigerGraph\n",
    "\n",
    "The following code defines the `TigerGraphStorage` class, which interfaces with **TigerGraphX** to manage graph data in TigerGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4105c86b-0a7b-4e6d-8f22-ac72b7f3b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict\n",
    "import numpy as np\n",
    "\n",
    "from lightrag.base import BaseGraphStorage\n",
    "from lightrag.utils import logger\n",
    "\n",
    "from tigergraphx import Graph\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TigerGraphStorage(BaseGraphStorage):\n",
    "    def __post_init__(self):\n",
    "        try:\n",
    "            # Define the graph schema\n",
    "            graph_schema = {\n",
    "                \"graph_name\": \"LightRAG\",\n",
    "                \"nodes\": {\n",
    "                    \"Entity\": {\n",
    "                        \"primary_key\": \"id\",\n",
    "                        \"attributes\": {\n",
    "                            \"id\": \"STRING\",\n",
    "                            \"entity_type\": \"STRING\",\n",
    "                            \"description\": \"STRING\",\n",
    "                            \"source_id\": \"STRING\",\n",
    "                        },\n",
    "                    }\n",
    "                },\n",
    "                \"edges\": {\n",
    "                    \"relationship\": {\n",
    "                        \"is_directed_edge\": False,\n",
    "                        \"from_node_type\": \"Entity\",\n",
    "                        \"to_node_type\": \"Entity\",\n",
    "                        \"attributes\": {\n",
    "                            \"weight\": \"DOUBLE\",\n",
    "                            \"description\": \"STRING\",\n",
    "                            \"keywords\": \"STRING\",\n",
    "                            \"source_id\": \"STRING\",\n",
    "                        },\n",
    "                    }\n",
    "                },\n",
    "            }\n",
    "\n",
    "            # Initialize the graph\n",
    "            self._graph = Graph(graph_schema)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during initialization: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_quotes(value: str) -> str:\n",
    "        \"\"\"Remove leading and trailing &quot; from a string if present.\"\"\"\n",
    "        if value.startswith('\"') and value.endswith('\"'):\n",
    "            return value[1:-1]\n",
    "        return value\n",
    "\n",
    "    async def has_node(self, node_id: str) -> bool:\n",
    "        return self._graph.has_node(self.clean_quotes(node_id))\n",
    "\n",
    "    async def has_edge(self, source_node_id: str, target_node_id: str) -> bool:\n",
    "        return self._graph.has_edge(\n",
    "            self.clean_quotes(source_node_id), self.clean_quotes(target_node_id)\n",
    "        )\n",
    "\n",
    "    async def node_degree(self, node_id: str) -> int:\n",
    "        result = self._graph.degree(self.clean_quotes(node_id))\n",
    "        return result\n",
    "\n",
    "    async def edge_degree(self, src_id: str, tgt_id: str) -> int:\n",
    "        return self._graph.degree(self.clean_quotes(src_id)) + self._graph.degree(\n",
    "            self.clean_quotes(tgt_id)\n",
    "        )\n",
    "\n",
    "    async def get_node(self, node_id: str) -> dict | None:\n",
    "        result = self._graph.get_node_data(self.clean_quotes(node_id))\n",
    "        return result\n",
    "\n",
    "    async def get_edge(self, source_node_id: str, target_node_id: str) -> dict | None:\n",
    "        result = self._graph.get_edge_data(\n",
    "            self.clean_quotes(source_node_id), self.clean_quotes(target_node_id)\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    async def get_node_edges(self, source_node_id: str) -> list[tuple[str, str]] | None:\n",
    "        source_node_id = self.clean_quotes(source_node_id)\n",
    "        if self._graph.has_node(source_node_id):\n",
    "            edges = self._graph.get_node_edges(source_node_id)\n",
    "            return list(edges)\n",
    "        return None\n",
    "\n",
    "    async def upsert_node(self, node_id: str, node_data: Dict[str, Any]):\n",
    "        node_id = self.clean_quotes(node_id)\n",
    "        self._graph.add_node(node_id, **node_data)\n",
    "\n",
    "    async def upsert_edge(\n",
    "        self, source_node_id: str, target_node_id: str, edge_data: Dict[str, Any]\n",
    "    ):\n",
    "        source_node_id = self.clean_quotes(source_node_id)\n",
    "        target_node_id = self.clean_quotes(target_node_id)\n",
    "        self._graph.add_edge(source_node_id, target_node_id, **edge_data)\n",
    "\n",
    "    async def delete_node(self, node_id: str):\n",
    "        if self._graph.has_node(node_id):\n",
    "            self._graph.remove_node(node_id)\n",
    "            logger.info(f\"Node {node_id} deleted from the graph.\")\n",
    "        else:\n",
    "            logger.warning(f\"Node {node_id} not found in the graph for deletion.\")\n",
    "\n",
    "    async def embed_nodes(self, algorithm: str) -> tuple[np.ndarray, list[str]]:\n",
    "        return np.array([]), []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dffac3d-df08-4a5e-ad8a-d33b83b58c64",
   "metadata": {},
   "source": [
    "#### Key Features:\n",
    "\n",
    "1. **Graph Schema**  \n",
    "   - Defines a node type `\"Entity\"` with attributes: `id`, `entity_type`, `description`, and `source_id`.\n",
    "   - Defines an edge type `\"relationship\"` with attributes: `weight`, `description`, and `source_id`.\n",
    "\n",
    "2. **Graph Initialization**  \n",
    "   - Initializes the graph schema using **TigerGraphX**.\n",
    "\n",
    "3. **Node and Edge Operations**  \n",
    "   - **Node Operations**:\n",
    "     - `has_node`: Checks if a node exists.\n",
    "     - `get_node`: Retrieves node data.\n",
    "     - `upsert_node`: Adds or updates a node.\n",
    "     - `delete_node`: Removes a node.\n",
    "   - **Edge Operations**:\n",
    "     - `has_edge`: Checks if an edge exists.\n",
    "     - `get_edge`: Retrieves edge data.\n",
    "     - `upsert_edge`: Adds or updates an edge.\n",
    "\n",
    "4. **Graph Metrics**  \n",
    "   - `node_degree`: Returns a node’s connection count.\n",
    "   - `edge_degree`: Computes the combined degrees of two nodes.\n",
    "\n",
    "5. **Utility Functions**  \n",
    "   - **`clean_quotes`**: Removes surrounding quotes from strings.\n",
    "   - **`drop_graph`**: Deletes the entire graph.\n",
    "\n",
    "#### Conclusion:\n",
    "The `TigerGraphStorage` class provides an efficient way to manage graph data in TigerGraph, offering straightforward methods for storing, retrieving, and handling nodes, edges, and graph metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458816c3-0c1f-434b-9a15-51d82d008f7f",
   "metadata": {},
   "source": [
    "### Implement Vector Storage with TigerGraph\n",
    "The following code defines the `TigerVectorStorage` class, which enables storing and querying vector data (such as embeddings) in a TigerGraph database using **TigerGraphX**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff8a65d-31aa-4fdb-8847-81a596b9988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "from tqdm.asyncio import tqdm as tqdm_async\n",
    "import asyncio\n",
    "\n",
    "from lightrag.base import BaseVectorStorage\n",
    "from lightrag.utils import logger\n",
    "\n",
    "from tigergraphx import Graph\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TigerVectorStorage(BaseVectorStorage):\n",
    "    def __post_init__(self):\n",
    "        try:\n",
    "            # Define the graph schema\n",
    "            graph_schema = {\n",
    "                \"graph_name\": f\"Vector_{self.namespace}\",\n",
    "                \"nodes\": {\n",
    "                    \"Table\": {\n",
    "                        \"primary_key\": \"id\",\n",
    "                        \"attributes\": {\n",
    "                            \"id\": \"STRING\",\n",
    "                            **{field: \"STRING\" for field in self.meta_fields},\n",
    "                        },\n",
    "                        \"vector_attributes\": {\n",
    "                            \"vector_attribute\": self.embedding_func.embedding_dim,\n",
    "                        },\n",
    "                    }\n",
    "                },\n",
    "                \"edges\": {},\n",
    "            }\n",
    "\n",
    "            # Initialize the graph\n",
    "            self._graph = Graph(graph_schema)\n",
    "            self._max_batch_size = self.global_config[\"embedding_batch_num\"]\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during initialization: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def upsert(self, data: dict[str, dict]):\n",
    "        \"\"\"\n",
    "        Insert or update data in the TigerGraph vector storage.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Inserting {len(data)} vectors to {self.namespace}\")\n",
    "        if not len(data):\n",
    "            logger.warning(\"No data to insert into the vector DB.\")\n",
    "            return []\n",
    "\n",
    "        # Preparing the data for insertion\n",
    "        list_data = [\n",
    "            {\n",
    "                \"id\": k,\n",
    "                **{k1: v1 for k1, v1 in v.items() if k1 in self.meta_fields},\n",
    "            }\n",
    "            for k, v in data.items()\n",
    "        ]\n",
    "\n",
    "        contents = [v[\"content\"] for v in data.values()]\n",
    "\n",
    "        # Batch the data for embedding\n",
    "        batches = [\n",
    "            contents[i : i + self._max_batch_size]\n",
    "            for i in range(0, len(contents), self._max_batch_size)\n",
    "        ]\n",
    "\n",
    "        async def wrapped_task(batch):\n",
    "            result = await self.embedding_func(batch)\n",
    "            pbar.update(1)\n",
    "            return result\n",
    "\n",
    "        embedding_tasks = [wrapped_task(batch) for batch in batches]\n",
    "        pbar = tqdm_async(\n",
    "            total=len(embedding_tasks), desc=\"Generating embeddings\", unit=\"batch\"\n",
    "        )\n",
    "        embeddings_list = await asyncio.gather(*embedding_tasks)\n",
    "\n",
    "        embeddings = np.concatenate(embeddings_list)\n",
    "        if len(embeddings) == len(list_data):\n",
    "            for i, d in enumerate(list_data):\n",
    "                d[\"vector_attribute\"] = embeddings[i].tolist()\n",
    "            results = self._graph.upsert(data=list_data, node_type=\"Table\")\n",
    "            return results\n",
    "        else:\n",
    "            # sometimes the embedding is not returned correctly. just log it.\n",
    "            logger.error(\n",
    "                f\"embedding is not 1-1 with data, {len(embeddings)} != {len(list_data)}\"\n",
    "            )\n",
    "\n",
    "    async def query(self, query: str, top_k=5):\n",
    "        \"\"\"\n",
    "        Perform a vector search to find the most similar nodes based on the query vector.\n",
    "        \"\"\"\n",
    "        embedding = await self.embedding_func([query])\n",
    "        embedding = embedding[0].tolist()\n",
    "        results = self._graph.search(\n",
    "            data=embedding,\n",
    "            vector_attribute_name=\"vector_attribute\",\n",
    "            node_type=\"Table\",  # Specify the node type\n",
    "            limit=top_k,  # Retrieve the top_k closest nodes\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec29acb-f516-49c2-99b2-321f290cc646",
   "metadata": {},
   "source": [
    "#### Key Features:\n",
    "\n",
    "1. **Graph Schema**  \n",
    "   - Defines a node type `\"Table\"` with attributes including an `id` and a vector field for storing embeddings.  \n",
    "   - The vector attribute's dimension is determined by the `embedding_func`.\n",
    "\n",
    "2. **Upsert Method**  \n",
    "   - Inserts or updates vector data in the TigerGraph database.  \n",
    "   - Batches the data and asynchronously generates embeddings using `embedding_func`, then stores them in the graph.\n",
    "\n",
    "3. **Query Method**  \n",
    "   - Performs vector search in the TigerGraph database to find the most similar nodes based on a query vector.  \n",
    "   - Uses `embedding_func` to generate the query vector and retrieves the closest nodes.\n",
    "\n",
    "#### Conclusion:\n",
    "`TigerVectorStorage` facilitates efficient storage and retrieval of vector embeddings in TigerGraph, enabling seamless integration of vector search capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09d175-8ab3-40bc-b969-793f94b6de4b",
   "metadata": {},
   "source": [
    "## Integrating Custom Graph and Vector Storage with LightRAG\n",
    "\n",
    "Once the `TigerGraphStorage` and `TigerVectorStorage` classes are defined, they can be integrated into LightRAG. By subclassing LightRAG and extending its storage mapping, you can seamlessly replace or enhance the default storage backends with custom implementations.\n",
    "\n",
    "Although modifying the LightRAG source code is an option, this example demonstrates how to achieve integration without altering the original code.\n",
    "\n",
    "Below is the implementation of `CustomLightRAG`, which incorporates `TigerGraphStorage` and `TigerVectorStorage` into its storage mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d68abb81-5185-4219-8e02-7a4e980675bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightrag import LightRAG\n",
    "from lightrag.lightrag import lazy_external_import\n",
    "\n",
    "\n",
    "class CustomLightRAG(LightRAG):\n",
    "    def _get_storage_class(self, storage_name: str) -> dict:\n",
    "        \"\"\"Override storage retrieval to use a custom storage mapping.\"\"\"\n",
    "\n",
    "        custom_storages = {\n",
    "            \"TigerGraphStorage\": \"__main__\",\n",
    "            \"TigerVectorStorage\": \"__main__\",\n",
    "        }\n",
    "\n",
    "        if storage_name in custom_storages:\n",
    "            import_path = custom_storages[storage_name]\n",
    "            return lazy_external_import(import_path, storage_name\n",
    "\n",
    "        # Call the parent class's method to prevent infinite recursion\n",
    "        return super()._get_storage_class(storage_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c446f6b0-2f2a-47e4-a161-c24c571ef06e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Indexing\n",
    "### Data Preparation\n",
    "For this demo, we will use `applications/lightrag/data` as the working directory.\n",
    "\n",
    "The input dataset, `input/clapnq_dev_answerable_orig.jsonl.10.txt`, is located in the working directory. It consists of the first ten records from the [original dataset](https://github.com/primeqa/clapnq/blob/main/original_documents/dev/clapnq_dev_answerable_orig.jsonl).\n",
    "\n",
    "Additionally, we have another dataset, `clapnq_dev_answerable.jsonl.10`, for evaluation, stored in `applications/resources`. This dataset contains ten questions from the [annotated dataset](https://github.com/primeqa/clapnq/blob/main/annotated_data/dev/clapnq_dev_answerable.jsonl), each with corresponding context from the original dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Indexing\n",
    "The following code sets up the working directory and demonstrates how to index a document using LightRAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd5da89-f256-40dd-ba5f-52a3bfbb59e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed\n",
    "\n",
    "import nest_asyncio\n",
    "# Allow nested event loops in Jupyter Notebook without conflicts\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "working_dir = \"../../applications/lightrag/data\"\n",
    "\n",
    "custom_rag = CustomLightRAG(\n",
    "    working_dir=working_dir,\n",
    "    embedding_func=openai_embed,\n",
    "    llm_model_func=gpt_4o_mini_complete,\n",
    "    graph_storage=\"TigerGraphStorage\",\n",
    "    vector_storage=\"TigerVectorStorage\",\n",
    "    kv_storage=\"JsonKVStorage\",\n",
    ")\n",
    "\n",
    "with open(working_dir + \"/input/clapnq_dev_answerable_orig.jsonl.10.txt\") as f:\n",
    "    custom_rag.insert(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4aa18b-fbe0-4980-b306-35bf971e69df",
   "metadata": {},
   "source": [
    "**Note:** The output has been cleared due to its length, as most of it consists of logs.\n",
    "\n",
    "Additionally, **TigerVector** is supported only in TigerGraph **v4.2.0 and later**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a68c67-9e55-4b57-82b1-c66a9c674f12",
   "metadata": {},
   "source": [
    "## Querying\n",
    "The following code demonstrates how to perform a query in LightRAG using the TigerGraph graph storage implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917a843d-40f1-4843-83d4-1eac4eb6869d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 20:21:58,215 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:23:21,681 - lightrag - INFO - Global query uses 70 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:23:21,683 - lightrag - INFO - Local query uses 60 entites, 32 relations, 3 text units\n",
      "------------------- Query Result:  -------------------\n",
      "### World's Largest Man-Made Lake\n",
      "\n",
      "The world's largest man-made lake is **Lake Kariba**, which is located on the Zambezi River, straddling the border between **Zambia** and **Zimbabwe**. The lake was created by the construction of the **Kariba Dam**, which significantly impacted the surrounding environment and local communities when it was completed between 1958 and 1963. \n",
      "\n",
      "### Key Features\n",
      "\n",
      "- **Size**: Lake Kariba has a surface area of approximately **5,580 square kilometers** and is known for its rich biodiversity, supporting various fish species and wildlife.\n",
      "- **Biodiversity**: The lake is home to numerous species, including **kapenta**, a fish introduced to enhance its ecological dynamics and commercial value.\n",
      "- **Economical Importance**: The lake plays a critical role in supporting the **tourism industry** for both Zambia and Zimbabwe, attracting visitors with its natural beauty and wildlife.\n",
      "\n",
      "Lake Kariba not only serves as a significant geographical landmark but also as a crucial resource for the economies of the surrounding nations.\n"
     ]
    }
   ],
   "source": [
    "from lightrag import QueryParam\n",
    "\n",
    "query = \"where is the world's largest man made lake\"\n",
    "\n",
    "result = custom_rag.query(query=query, param=QueryParam(mode=\"hybrid\"))\n",
    "\n",
    "print(\"------------------- Query Result:  -------------------\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8054265b-471c-480a-a62e-713d26dec7ba",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "To evaluate the performance of LightRAG, we use TigerGraphX's `RagasEvaluator` class, which leverages Ragas for evaluation.\n",
    "\n",
    "In the code below, we define the `prepare_evaluation_data` function to construct the evaluation dataset. This function processes `ragas_data` by extracting questions and ground-truth answers, then queries `custom_rag` to retrieve both context passages and generated responses. The extracted data is then structured into evaluation samples, where each sample includes the question, retrieved contexts, generated answer, and ground-truth answers from the `clapnq_dev_answerable.jsonl.10` dataset stored in `applications/resources`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e895a7bf-3963-41d1-bfe6-2511ba756957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, cast\n",
    "\n",
    "from tigergraphx.graphrag import RagasEvaluator\n",
    "\n",
    "def query_light_rag(\n",
    "    custom_rag,\n",
    "    query,\n",
    "    mode: Literal[\"naive\", \"hybrid\"] = \"hybrid\",\n",
    "    only_context=False,\n",
    "):\n",
    "    \"\"\"Query LightRAG to retrieve context or generated responses.\"\"\"\n",
    "    param = QueryParam(mode=mode, only_need_context=only_context)\n",
    "    result = custom_rag.query(query=query, param=param)\n",
    "    return result\n",
    "\n",
    "\n",
    "def prepare_evaluation_data(\n",
    "    custom_rag,\n",
    "    ragas_data,\n",
    "    mode: Literal[\"naive\", \"hybrid\"] = \"hybrid\",\n",
    "):\n",
    "    \"\"\"Prepare evaluation dataset using queries from ragas_data.\"\"\"\n",
    "    eval_samples = []\n",
    "\n",
    "    for row in ragas_data:\n",
    "        question = row[\"input\"]  # Adjust to match dataset structure\n",
    "        ground_truths = [\n",
    "            ans[\"answer\"] for ans in row[\"output\"]\n",
    "        ]  # Extract ground truth answers\n",
    "\n",
    "        # Extract passages from the dataset (context retrieval)\n",
    "        retrieved_contexts = query_light_rag(\n",
    "            custom_rag, question, mode, only_context=True\n",
    "        )\n",
    "\n",
    "        # Extract generated response from LightRAG\n",
    "        response = query_light_rag(custom_rag, question, mode, only_context=False)\n",
    "\n",
    "        eval_samples.append(\n",
    "            {\n",
    "                \"question\": question,\n",
    "                \"contexts\": retrieved_contexts\n",
    "                if isinstance(retrieved_contexts, list)\n",
    "                else [retrieved_contexts],\n",
    "                \"answer\": response,\n",
    "                \"ground_truth\": ground_truths,\n",
    "            }\n",
    "        )\n",
    "    return eval_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7021ce-82e4-460f-a63c-926a057386ac",
   "metadata": {},
   "source": [
    "Next, we load the evaluation dataset from `clapnq_dev_answerable.jsonl.10`, which contains queries and ground-truth answers. We then use the `prepare_evaluation_data` function to generate evaluation samples by retrieving context passages and responses from `custom_rag`.\n",
    "\n",
    "Once the evaluation dataset is prepared, we initialize the `RagasEvaluator` with the `gpt-4o` model and run the evaluation to assess LightRAG's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab08e512-9f89-4c44-b96a-ddc44b9fe39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 20:31:01,776 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:32:24,563 - lightrag - INFO - Global query uses 53 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:32:24,565 - lightrag - INFO - Local query uses 60 entites, 24 relations, 3 text units\n",
      "2025-02-28 20:32:24,647 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:32:34,144 - lightrag - INFO - Global query uses 53 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:32:34,146 - lightrag - INFO - Local query uses 60 entites, 24 relations, 3 text units\n",
      "2025-02-28 20:32:41,812 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:33:44,706 - lightrag - INFO - Global query uses 76 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:33:47,394 - lightrag - INFO - Local query uses 60 entites, 40 relations, 3 text units\n",
      "2025-02-28 20:33:47,425 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:33:55,750 - lightrag - INFO - Global query uses 76 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:33:57,289 - lightrag - INFO - Local query uses 60 entites, 40 relations, 3 text units\n",
      "2025-02-28 20:34:03,817 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:35:07,504 - lightrag - INFO - Global query uses 59 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:35:10,693 - lightrag - INFO - Local query uses 60 entites, 39 relations, 3 text units\n",
      "2025-02-28 20:35:10,724 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:35:19,992 - lightrag - INFO - Global query uses 59 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:35:21,489 - lightrag - INFO - Local query uses 60 entites, 39 relations, 3 text units\n",
      "2025-02-28 20:35:26,577 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:35:47,741 - lightrag - WARNING - Some nodes are missing, maybe the storage is damaged\n",
      "2025-02-28 20:36:22,940 - lightrag - INFO - Global query uses 71 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:36:22,943 - lightrag - INFO - Local query uses 58 entites, 37 relations, 3 text units\n",
      "2025-02-28 20:36:22,982 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:36:28,583 - lightrag - WARNING - Some nodes are missing, maybe the storage is damaged\n",
      "2025-02-28 20:36:30,848 - lightrag - INFO - Global query uses 71 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:36:32,222 - lightrag - INFO - Local query uses 58 entites, 37 relations, 3 text units\n",
      "2025-02-28 20:36:36,151 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:37:35,089 - lightrag - INFO - Global query uses 59 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:38:01,468 - lightrag - INFO - Local query uses 60 entites, 125 relations, 3 text units\n",
      "2025-02-28 20:38:01,517 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:38:10,021 - lightrag - INFO - Global query uses 59 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:38:16,022 - lightrag - INFO - Local query uses 60 entites, 125 relations, 3 text units\n",
      "2025-02-28 20:38:21,065 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:39:28,932 - lightrag - INFO - Global query uses 61 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:39:28,935 - lightrag - INFO - Local query uses 60 entites, 95 relations, 3 text units\n",
      "2025-02-28 20:39:28,977 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:39:40,160 - lightrag - INFO - Global query uses 61 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:39:40,162 - lightrag - INFO - Local query uses 60 entites, 95 relations, 3 text units\n",
      "2025-02-28 20:39:51,972 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:39:52,129 - openai._base_client - INFO - Retrying request to /embeddings in 0.436530 seconds\n",
      "2025-02-28 20:40:52,287 - lightrag - INFO - Global query uses 68 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:40:52,290 - lightrag - INFO - Local query uses 60 entites, 36 relations, 3 text units\n",
      "2025-02-28 20:40:52,339 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:41:01,041 - lightrag - INFO - Global query uses 68 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:41:02,383 - lightrag - INFO - Local query uses 60 entites, 36 relations, 3 text units\n",
      "2025-02-28 20:41:10,024 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:41:31,041 - lightrag - WARNING - Some nodes are missing, maybe the storage is damaged\n",
      "2025-02-28 20:42:11,316 - lightrag - INFO - Global query uses 81 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:42:11,319 - lightrag - INFO - Local query uses 57 entites, 43 relations, 3 text units\n",
      "2025-02-28 20:42:11,351 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:42:17,018 - lightrag - WARNING - Some nodes are missing, maybe the storage is damaged\n",
      "2025-02-28 20:42:19,114 - lightrag - INFO - Global query uses 81 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:42:20,809 - lightrag - INFO - Local query uses 57 entites, 43 relations, 3 text units\n",
      "2025-02-28 20:42:30,206 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:42:30,375 - openai._base_client - INFO - Retrying request to /embeddings in 0.428693 seconds\n",
      "2025-02-28 20:43:28,485 - lightrag - INFO - Global query uses 56 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:43:43,044 - lightrag - INFO - Local query uses 60 entites, 109 relations, 3 text units\n",
      "2025-02-28 20:43:43,080 - lightrag - INFO - Using hybrid mode for query processing\n",
      "2025-02-28 20:43:47,577 - lightrag - INFO - Global query uses 56 entites, 60 relations, 3 text units\n",
      "2025-02-28 20:43:48,136 - openai._base_client - INFO - Retrying request to /embeddings in 0.396963 seconds\n",
      "2025-02-28 20:43:58,277 - lightrag - INFO - Local query uses 60 entites, 109 relations, 3 text units\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1035a2a353243659e9d2733fe311fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 20:44:08,812 - openai._base_client - INFO - Retrying request to /chat/completions in 0.480058 seconds\n",
      "2025-02-28 20:44:08,814 - openai._base_client - INFO - Retrying request to /chat/completions in 0.397422 seconds\n",
      "2025-02-28 20:47:02,781 - ragas.executor - ERROR - Exception raised in Job[3]: TimeoutError()\n",
      "2025-02-28 20:47:02,788 - ragas.executor - ERROR - Exception raised in Job[2]: TimeoutError()\n",
      "2025-02-28 20:47:03,337 - tigergraphx.graphrag.evaluation.ragas_evaluator - INFO - Evaluation results: {'answer_relevancy': 0.8976, 'faithfulness': 0.6659, 'llm_context_precision_with_reference': 0.5556, 'context_recall': 0.4444}\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "# Load datasets\n",
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files=\"../../applications/resources/clapnq_dev_answerable.jsonl.10\",\n",
    "    split=\"train\",\n",
    ")\n",
    "dataset = cast(Dataset, dataset)\n",
    "\n",
    "# Prepare evaluation dataset\n",
    "eval_samples = prepare_evaluation_data(custom_rag, dataset, \"hybrid\")\n",
    "\n",
    "# Evaluate LightRAG\n",
    "evaluator = RagasEvaluator(model=\"gpt-4o\")\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluator.evaluate_dataset(eval_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dc6f47-6dfe-45b3-a2c6-f043d2ad5435",
   "metadata": {},
   "source": [
    "The final line displays the evaluation results:\n",
    "\n",
    "`Evaluation results: {'answer_relevancy': 0.8976, 'faithfulness': 0.6659, 'llm_context_precision_with_reference': 0.5556, 'context_recall': 0.4444}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05eaa4e-1542-462a-b478-ef06f57c1f87",
   "metadata": {},
   "source": [
    "---\n",
    "## Reset\n",
    "\n",
    "After completing the evaluation, it is recommended to clean up the environment by removing the previously created graphs. The following code iterates through a list of graph names and attempts to drop each graph from the TigerGraph database. If a graph does not exist or an error occurs during deletion, the error message is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1e348df-8387-4a3e-bd97-af2fb1528c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-28 20:50:07,250 - tigergraphx.core.managers.schema_manager - INFO - Dropping graph: LightRAG...\n",
      "2025-02-28 20:50:10,802 - tigergraphx.core.managers.schema_manager - INFO - Graph dropped successfully.\n",
      "2025-02-28 20:50:10,840 - tigergraphx.core.managers.schema_manager - INFO - Dropping graph: Vector_chunks...\n",
      "2025-02-28 20:50:14,019 - tigergraphx.core.managers.schema_manager - INFO - Graph dropped successfully.\n",
      "2025-02-28 20:50:14,050 - tigergraphx.core.managers.schema_manager - INFO - Dropping graph: Vector_entities...\n",
      "2025-02-28 20:50:17,205 - tigergraphx.core.managers.schema_manager - INFO - Graph dropped successfully.\n",
      "2025-02-28 20:50:17,268 - tigergraphx.core.managers.schema_manager - INFO - Dropping graph: Vector_relationships...\n",
      "2025-02-28 20:50:20,638 - tigergraphx.core.managers.schema_manager - INFO - Graph dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "from tigergraphx import Graph\n",
    "\n",
    "graphs_to_drop = [\n",
    "    \"LightRAG\",\n",
    "    \"Vector_chunks\",\n",
    "    \"Vector_entities\",\n",
    "    \"Vector_relationships\",\n",
    "]\n",
    "for graph_name in graphs_to_drop:\n",
    "    try:\n",
    "        G = Graph.from_db(graph_name)\n",
    "        G.drop_graph()\n",
    "    except Exception as e:\n",
    "        print(f\"Error message: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60bd63-9420-4e74-9a48-c57576bb1f62",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Supporting Microsoft’s GraphRAG: Part 1](msft_graphrag_1.md): Demonstrates how to integrate TigerGraph with Microsoft's GraphRAG.\n",
    "\n",
    "---\n",
    "\n",
    "Start transforming your GraphRAG workflows with the power of **TigerGraphX** today!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
